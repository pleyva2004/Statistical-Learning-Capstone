{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0674ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 01:23:50.382340: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-20 01:23:50.390926: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1758345830.400592  119723 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1758345830.404369  119723 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-09-20 01:23:50.415680: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d6e87e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.13)\n"
     ]
    }
   ],
   "source": [
    "path = kagglehub.dataset_download(\"nikhil7280/student-performance-multiple-linear-regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "982f5b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Student_Performance.csv\n",
      "   Hours Studied  Previous Scores Extracurricular Activities  Sleep Hours  \\\n",
      "0              7               99                        Yes            9   \n",
      "1              4               82                         No            4   \n",
      "2              8               51                        Yes            7   \n",
      "3              5               52                        Yes            5   \n",
      "4              7               75                         No            8   \n",
      "\n",
      "   Sample Question Papers Practiced  Performance Index  \n",
      "0                                 1               91.0  \n",
      "1                                 2               65.0  \n",
      "2                                 2               45.0  \n",
      "3                                 2               36.0  \n",
      "4                                 5               66.0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "files = os.listdir(path)\n",
    "csv_files = [f for f in files if f.endswith('.csv')]\n",
    "\n",
    "if csv_files:\n",
    "    # Load the first CSV file found\n",
    "    csv_file = csv_files[0]\n",
    "    csv_path = os.path.join(path, csv_file)\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(f\"Loaded {csv_file}\")\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ef1962b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Basic cleaning / column selection\n",
    "target = \"Performance Index\"\n",
    "feature_names = [\n",
    "    \"Hours Studied\",\n",
    "    \"Previous Scores\",\n",
    "    \"Extracurricular Activities\",   # often 0/1\n",
    "    \"Sleep Hours\",\n",
    "    \"Sample Question Papers Practiced\"\n",
    "]\n",
    "X = df[feature_names].copy()\n",
    "y = df[target].astype(float)\n",
    "\n",
    "# If Extracurricular Activities is 'Yes'/'No', convert to 1/0:\n",
    "if X[\"Extracurricular Activities\"].dtype == object:\n",
    "    X[\"Extracurricular Activities\"] = X[\"Extracurricular Activities\"].str.strip().str.lower().map({\"yes\":1, \"no\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dde7c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/val/test split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X.values, y.values, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test   = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "190a49a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1758345832.484051  119723 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5520 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "normalizer = tf.keras.layers.Normalization()\n",
    "normalizer.adapt(X_train) # fit on train only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "693de074",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_119723/2867436087.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  return W, float(b)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m lam \u001b[38;5;129;01min\u001b[39;00m lams:\n\u001b[32m     27\u001b[39m     model_lam = build_model(lam, X_train.shape[\u001b[32m1\u001b[39m], normalizer=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     \u001b[43mmodel_lam\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m                  \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m     betas, bias = betas_on_original_scale(model_lam, normalizer=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     31\u001b[39m     coef_paths.append(betas)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:377\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    376\u001b[39m     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m     callbacks.on_train_batch_end(end_step, logs)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:221\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m     iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m ):\n\u001b[32m    220\u001b[39m     opt_outputs = multi_step_on_iterator(iterator)\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    222\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m opt_outputs.get_value()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:321\u001b[39m, in \u001b[36m_EagerTensorBase.__bool__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m__bool__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m321\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:381\u001b[39m, in \u001b[36m_EagerTensorBase._numpy\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> npt.ArrayLike:\n\u001b[32m    380\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m381\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    382\u001b[39m   \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m    383\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m core._status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def betas_on_original_scale(model, normalizer=None):\n",
    "    dense = next(l for l in model.layers if isinstance(l, tf.keras.layers.Dense))\n",
    "    W, b = dense.get_weights()         # W: (n_features,1)\n",
    "    W = W[:,0]\n",
    "    if normalizer is None:\n",
    "        return W, float(b)\n",
    "    means = normalizer.get_mean().numpy()\n",
    "    stds  = np.sqrt(normalizer.get_variance().numpy())\n",
    "    beta  = W / stds\n",
    "    beta0 = b - np.sum(means * beta)\n",
    "    return beta, float(beta0)\n",
    "\n",
    "def build_model(lambda_l2, n_feats, normalizer=None):\n",
    "    inp = keras.Input(shape=(n_feats,))\n",
    "    x = inp if normalizer is None else normalizer(inp)\n",
    "    out = keras.layers.Dense(1, activation=None,\n",
    "                             kernel_regularizer=keras.regularizers.l2(lambda_l2))(x)\n",
    "    m = keras.Model(inp, out)\n",
    "    m.compile(optimizer=keras.optimizers.Adam(1e-2), loss=\"mse\")\n",
    "    return m\n",
    "\n",
    "lams = np.concatenate([[0], np.logspace(-6, 1, 19)])  # Start with 0, then exponential spacing\n",
    "coef_paths = []\n",
    "bias_paths = []\n",
    "\n",
    "for lam in lams:\n",
    "    model_lam = build_model(lam, X_train.shape[1], normalizer=None)\n",
    "    model_lam.fit(X_train, y_train, epochs=200, batch_size=32,\n",
    "                  validation_data=(X_val, y_val), verbose=0)\n",
    "    betas, bias = betas_on_original_scale(model_lam, normalizer=None)\n",
    "    coef_paths.append(betas)\n",
    "    bias_paths.append(bias)\n",
    "\n",
    "coef_paths = np.array(coef_paths)  # shape: (n_lams, n_features)\n",
    "bias_paths = np.array(bias_paths)  # shape: (n_lams,)\n",
    "\n",
    "# Create a single plot with all 6 parameters\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Define colors for each line\n",
    "colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown']\n",
    "\n",
    "# Plot coefficients for each feature\n",
    "for j, name in enumerate(feature_names):\n",
    "    plt.plot(lams, coef_paths[:, j], color=colors[j], linewidth=2, \n",
    "             label=f'w{j+1}: {name}', marker='o', markersize=3)\n",
    "\n",
    "# Plot bias term\n",
    "plt.plot(lams, bias_paths, color=colors[5], linewidth=2, \n",
    "         label='Bias (w0)', marker='s', markersize=3)\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Lambda (L2 Regularization Strength)\", fontsize=12)\n",
    "plt.ylabel(\"Parameter Values (Original Scale)\", fontsize=12)\n",
    "plt.title(\"Ridge Regression Coefficient Paths\\n(All Parameters vs Lambda)\", fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Optional: Also create a linear scale version to better see the lambda=0 point\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot the first few lambda values on linear scale to better see the OLS point\n",
    "lams_subset = lams[:10]  # First 10 lambda values including 0\n",
    "coef_subset = coef_paths[:10]\n",
    "bias_subset = bias_paths[:10]\n",
    "\n",
    "for j, name in enumerate(feature_names):\n",
    "    plt.plot(lams_subset, coef_subset[:, j], color=colors[j], linewidth=2, \n",
    "             label=f'w{j+1}: {name}', marker='o', markersize=4)\n",
    "\n",
    "plt.plot(lams_subset, bias_subset, color=colors[5], linewidth=2, \n",
    "         label='Bias (w0)', marker='s', markersize=4)\n",
    "\n",
    "plt.xlabel(\"Lambda (L2 Regularization Strength)\", fontsize=12)\n",
    "plt.ylabel(\"Parameter Values (Original Scale)\", fontsize=12)\n",
    "plt.title(\"Ridge Regression Coefficient Paths (Linear Scale - First 10 Lambda Values)\", fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
